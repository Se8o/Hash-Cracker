# Parallel Hash Cracking Engine

Professional cybersecurity tool for secure hash verification and lookup using parallel processing with Python's multiprocessing.

## ğŸ¯ Project Description

This engine leverages **true parallelism** through `multiprocessing.Process` to efficiently process large datasets and compare cryptographic hashes across multiple CPU cores. Designed for legitimate cybersecurity purposes including penetration testing, security audits, and educational demonstrations.

### Key Features

- âœ… **True Parallelism**: Uses `multiprocessing`, not threading or asyncio
- âœ… **Multiple Hash Algorithms**: SHA256, SHA384, SHA512, PBKDF2-HMAC
- âœ… **Producer-Consumer Pattern**: Queue-based task distribution
- âœ… **Shared Memory**: `Manager.dict()` and `Manager.Queue()`
- âœ… **Synchronization**: Lock and Semaphore mechanisms
- âœ… **Chunking**: Efficient data distribution to workers
- âœ… **Thread-Safe Logging**: Multiprocessing-safe logger with Lock
- âœ… **Comprehensive Testing**: Unit tests for all components
- âœ… **Standard Library Only**: No heavy dependencies

## ğŸ“‹ Requirements

- Python 3.7 or higher
- Standard library only (no external dependencies)

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/Se8o/Hasher.git
cd Hasher
```

2. No additional dependencies to install - uses Python standard library only!

## ğŸ“ Project Structure

```
Hasher/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # Main pipeline orchestrator
â”‚   â”œâ”€â”€ config_loader.py           # Configuration management
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ receiver.py            # CSV data loader and chunker
â”‚   â”‚   â”œâ”€â”€ task_queue.py          # Task distribution queue
â”‚   â”‚   â”œâ”€â”€ worker.py              # Parallel worker processes
â”‚   â”‚   â”œâ”€â”€ collector.py           # Result collector
â”‚   â”‚   â”œâ”€â”€ hasher.py              # Hash computation engine
â”‚   â”‚   â””â”€â”€ logger.py              # Thread-safe logger
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ timer.py               # Execution timer
â”‚       â”œâ”€â”€ chunker.py             # Data chunking utilities
â”‚       â””â”€â”€ validator.py           # Validation functions
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ test_hasher.py             # Hash engine tests
â”‚   â”œâ”€â”€ test_pipeline.py           # Pipeline integration tests
â”‚   â””â”€â”€ test_config.py             # Configuration tests
â”œâ”€â”€ doc/
â”‚   â””â”€â”€ documentation.md           # Complete technical documentation
â”œâ”€â”€ data/                          # Input CSV files
â”œâ”€â”€ logs/                          # Log and result files
â””â”€â”€ config.json                    # Configuration file
```

## âš™ï¸ Configuration

Edit `config.json` to configure the engine:

```json
{
  "general": {
    "worker_count": 4,
    "chunk_size": 10000,
    "max_workers": 8,
    "timeout_seconds": 300
  },
  "hash": {
    "algorithm": "SHA256",
    "pbkdf2_iterations": 100000,
    "pbkdf2_salt_length": 32
  },
  "input": {
    "csv_path": "data/sample_data.csv",
    "csv_encoding": "utf-8",
    "csv_delimiter": ","
  },
  "output": {
    "log_path": "logs/hasher.log",
    "results_path": "logs/results.json",
    "verbose": true
  },
  "target": {
    "hash_to_find": "9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08"
  }
}
```

### Configuration Options

| Option | Description | Default |
|--------|-------------|---------|
| `worker_count` | Number of parallel worker processes | 4 |
| `chunk_size` | Number of items per chunk | 10000 |
| `algorithm` | Hash algorithm (SHA256/SHA384/SHA512/PBKDF2) | SHA256 |
| `csv_path` | Path to input CSV file | data/sample_data.csv |
| `hash_to_find` | Target hash to search for | "" |

## ğŸ“ Usage

### Basic Usage

1. Create a CSV file with data to hash (e.g., `data/sample_data.csv`):
```csv
test1
test2
test3
password
admin
user123
```

2. Configure the target hash in `config.json`:
```json
{
  "target": {
    "hash_to_find": "9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08"
  }
}
```

3. Run the engine:
```bash
python src/main.py
```

### Custom Configuration

```bash
python src/main.py custom_config.json
```

### Example Output

```
============================================================
PARALLEL HASH CRACKING ENGINE
============================================================
INFO - Validating pipeline setup...
INFO - Validation passed
INFO - Creating 4 worker processes...
INFO - Started 4 workers
INFO - Loaded 10 chunks into queue
INFO - Worker 0 started processing waiting for tasks
INFO - Worker 1 started processing waiting for tasks
INFO - Worker 2 FOUND MATCH: test -> 9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08
INFO - Worker 2 completed: 2500 items in 1.23s

============================================================
MATCHES FOUND: 1
============================================================

Match #1:
  Worker ID:  2
  Original:   test
  Hash:       9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08
  Algorithm:  SHA256

============================================================
INFO - Pipeline completed in 2.45s
INFO - Total items processed: 10000
INFO - Matches found: 1
INFO - Processing rate: 4081.63 items/sec
============================================================
```

## ğŸ“Š Example CSV Files

### Birth Numbers (RodnÃ¡ ÄÃ­sla)
```csv
# data/birth_numbers.csv
9001011234
8512251234
7503031234
9510155678
```

### Passwords
```csv
# data/passwords.csv
password
123456
admin
letmein
qwerty
```

### Generic Data
```csv
# data/sample_data.csv
test
hello
world
data123
```

## ğŸ§ª Running Tests

Run all tests:
```bash
python -m unittest discover test
```

Run specific test file:
```bash
python -m unittest test.test_hasher
python -m unittest test.test_pipeline
python -m unittest test.test_config
```

## ğŸ”§ Hash Algorithms

### SHA256 (Default)
- **Length**: 64 hex characters
- **Use case**: General purpose, fast
- **Example**: `9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08`

### SHA384
- **Length**: 96 hex characters
- **Use case**: Enhanced security
- **Example**: `768412320f7b0aa5812fce428dc4706b3cae50e02a64caa16a782249bfe8efc4b7ef1ccb126255d196047dfedf17a0a9`

### SHA512
- **Length**: 128 hex characters
- **Use case**: Maximum security
- **Example**: `ee26b0dd4af7e749aa1a8ee3c10ae9923f618980772e473f8819a5d4940e0db27ac185f8a0e1d5f84f88bc887fd67b143732c304cc5fa9ad8e6f57f50028a8ff`

### PBKDF2-HMAC-SHA256
- **Length**: Variable (salt + key)
- **Use case**: Password hashing (salted & iterated)
- **Iterations**: Configurable (default: 100,000)

## ğŸ“ Educational Value

This project demonstrates:

1. **Multiprocessing Concepts**
   - `multiprocessing.Process` for true parallelism
   - `Manager.Queue()` for task distribution
   - `Manager.dict()` for shared memory
   - Process synchronization

2. **Parallel Patterns**
   - Producer-Consumer pattern
   - Worker pool architecture
   - Poison pill termination

3. **Synchronization Mechanisms**
   - `Lock` for thread-safe logging
   - `Semaphore` for worker limiting
   - Shared memory management

4. **Software Engineering**
   - Clean architecture
   - Comprehensive testing
   - Error handling
   - Professional documentation

## âš ï¸ Security & Ethics

### Legitimate Uses
âœ… Authorized penetration testing  
âœ… Security audits with permission  
âœ… Educational purposes  
âœ… Database integrity verification  

### Prohibited Uses
âŒ Unauthorized access attempts  
âŒ Illegal password cracking  
âŒ Privacy violations  

**Use responsibly and only on systems you own or have explicit permission to test.**

## ğŸ“ˆ Performance Tips

### Optimal Worker Count
- Set to number of CPU cores for CPU-bound tasks
- Check available cores: `python -c "import os; print(os.cpu_count())"`

### Chunk Size
- **Small chunks (100-1,000)**: Better load balancing, more overhead
- **Large chunks (10,000-100,000)**: Less overhead, potential imbalance
- **Recommended**: 1,000-10,000 for most use cases

### Memory Considerations
- Entire CSV is loaded into memory
- For very large files, consider implementing streaming

## ğŸ› Troubleshooting

### Workers hang or timeout
- Check `timeout_seconds` in config
- Verify poison pills are sent correctly
- Review worker logs

### No matches found
- Verify target hash format (correct length, hex characters)
- Ensure algorithm matches hash type
- Check case sensitivity (normalized to lowercase)

### Permission denied
- Ensure read access to input CSV
- Ensure write access to logs directory
- Create output directories if missing

### Memory errors
- Reduce `chunk_size`
- Reduce `worker_count`
- Process file in batches

## ğŸ“š Documentation

Complete technical documentation available in:
- [doc/documentation.md](doc/documentation.md) - Architecture, UML diagrams, component details

## ğŸ¤ Contributing

This is an educational project. For improvements:
1. Fork the repository
2. Create a feature branch
3. Add tests for new features
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

Educational project - use responsibly and ethically.

## ğŸ‘¨â€ğŸ’» Author

Built as a demonstration of parallel computing concepts in Python for cybersecurity applications.

## ğŸ”— Related Concepts

- Multiprocessing vs Threading vs Asyncio
- Producer-Consumer pattern
- Hash functions in cryptography
- Parallel computing in Python
- Process synchronization
- Cybersecurity tools development

---

**Note**: This tool is designed for educational and authorized security testing purposes only. Always obtain proper authorization before testing any systems.
